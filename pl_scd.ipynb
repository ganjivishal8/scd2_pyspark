{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Connection Variables\n",
    "\n",
    "url=\"jdbc:postgresql://localhost:5432/scd_2\"\n",
    "source_name='source_scd'\n",
    "dest_name='dest_scd'\n",
    "username='postgres'\n",
    "password='Vish@08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globally Used Variables\n",
    "\n",
    "def_timestamp=\"9999-12-31 23:59:59\"\n",
    "key_list=[\"id\"]\n",
    "type2_cols=[\"company\",\"role\"]\n",
    "scd2_cols = [\"effective_date\",\"expiration_date\",\"current_flag\"]\n",
    "DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for wrting to database\n",
    "#option(\"truncate\",True).\\\n",
    "def writetoDb(df,url,table_name,username,password):\n",
    "    df.write.format(\"jdbc\"). \\\n",
    "                option(\"url\", url). \\\n",
    "                option(\"driver\", \"org.postgresql.Driver\"). \\\n",
    "                option(\"dbtable\", table_name). \\\n",
    "                option(\"user\", username). \\\n",
    "                option(\"password\", password). \\\n",
    "                mode(\"overwrite\").save()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read from Database\n",
    "def readfromDb(url,table_name,username,password):\n",
    "    df=spark.read.format(\"jdbc\"). \\\n",
    "                option(\"url\", url). \\\n",
    "                option(\"driver\", \"org.postgresql.Driver\"). \\\n",
    "                option(\"dbtable\", table_name). \\\n",
    "                option(\"user\", username). \\\n",
    "                option(\"password\", password). \\\n",
    "                load()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------+--------------------+\n",
      "| id|first_name| last_name|  company|                role|\n",
      "+---+----------+----------+---------+--------------------+\n",
      "|  1|  Crawford|    Hurich|    Fadeo|              Worker|\n",
      "|  2|    Karlik|   Barthot|   Kwideo|Construction Manager|\n",
      "|  4|     Elden|    Berger|    Jazzy|Construction Foreman|\n",
      "|  5|       Jon|  Bairstow|    Engla|             Creator|\n",
      "|  6|   Ferrell|Hungerford|  Feedbug|           Developer|\n",
      "|  7|    Evonne|    Benoit|  Blogtag|Construction Manager|\n",
      "|  8|     Nixie|  Goldring| Dabshots|       DataScientist|\n",
      "|  9|Christophe| Churchill|Skynoodle|           Architect|\n",
      "| 10|     Booth| Leathwood|   Yambee| Construction Worker|\n",
      "+---+----------+----------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Intially we have data in source table\n",
    "src_df=spark.read.csv(r'D:\\pyspark practice\\Data_Processing\\scd2\\employee.csv',header=True)\n",
    "src_df=src_df.withColumn('id',col('id').cast('int'))\n",
    "src_df.show()\n",
    "\n",
    "writetoDb(src_df,url,\"source_scd\",username,password)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------+--------------------+-----+-------------------+-------------------+----+\n",
      "| id|first_name| last_name|  company|                role|sk_id|     effective_date|    expiration_date|flag|\n",
      "+---+----------+----------+---------+--------------------+-----+-------------------+-------------------+----+\n",
      "|  1|  Crawford|    Hurich|    Fadeo|              Worker|    1|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  2|    Karlik|   Barthot|   Kwideo|Construction Manager|    2|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  4|     Elden|    Berger|    Jazzy|Construction Foreman|    3|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  5|       Jon|  Bairstow|    Engla|             Creator|    4|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  6|   Ferrell|Hungerford|  Feedbug|           Developer|    5|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  7|    Evonne|    Benoit|  Blogtag|Construction Manager|    6|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  8|     Nixie|  Goldring| Dabshots|       DataScientist|    7|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "|  9|Christophe| Churchill|Skynoodle|           Architect|    8|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "| 10|     Booth| Leathwood|   Yambee| Construction Worker|    9|2023-11-28 14:19:33|9999-12-31 23:59:59|true|\n",
      "+---+----------+----------+---------+--------------------+-----+-------------------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Taking current dataframe and adding necessary columns to to store in destination table\n",
    "\n",
    "current_df=readfromDb(url,\"source_scd\",username,password)\n",
    "\n",
    "window_spec=Window.orderBy('id')\n",
    "\n",
    "current_df=current_df.withColumn('sk_id',row_number().over(window_spec)).\\\n",
    "            withColumn('effective_date',date_format(current_timestamp(),DATE_FORMAT)).\\\n",
    "            withColumn('expiration_date',date_format(lit(def_timestamp),DATE_FORMAT)).\\\n",
    "            withColumn('flag',lit(True))\n",
    "\n",
    "current_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the current df to destination table\n",
    "\n",
    "writetoDb(current_df,url,\"dest_scd\",username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "####SCD_2 Implemnatation\n",
    "# 1)filtering open (true) records from dest table\n",
    "# 2)Creating Dataframe having renamed(_history) dest table and adding hash value\n",
    "#   Creating Dataframe having renamed(_current)  source table and adding hash value\n",
    "# 3)Merging table with full outer join and adding Action Column(NOCHANGE<INSERT<UPDATE<DELETE)\n",
    "# 4)Individually taking out all the rows with particular Action\n",
    "# 5)Merging All the rows and pushing into destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing Renaming Function, Generating Hash\n",
    "\n",
    "def rename(df,suffix,append):\n",
    "    if append:\n",
    "        new_cols=list(map(lambda x:x+suffix,df.columns))\n",
    "    else:\n",
    "        new_cols=list(map(lambda x:x.replace(suffix,\"\"),df.columns))\n",
    "    \n",
    "    return df.toDF(*new_cols)\n",
    "\n",
    "def getHash(df,key_list):\n",
    "    columns = [col(column) for column in key_list]\n",
    "    if columns:\n",
    "        return df.withColumn(\"hash_md5\", md5(concat_ws(\"\", *columns)))\n",
    "    else:\n",
    "        return df.withColumn(\"hash_md5\", md5(lit(1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------+--------------------+\n",
      "| id|first_name| last_name|  company|                role|\n",
      "+---+----------+----------+---------+--------------------+\n",
      "|  1|  Crawford|    Hurich|    Fadeo|              Worker|\n",
      "|  2|    Karlik|   Barthot|   Kwideo|Construction Manager|\n",
      "|  4|     Elden|    Berger|    Jazzy|Construction Foreman|\n",
      "|  5|       Jon|  Bairstow|    Engla|             Creator|\n",
      "|  6|   Ferrell|Hungerford|  Feedbug|           Developer|\n",
      "|  7|    Evonne|    Benoit|  Blogtag|Construction Manager|\n",
      "|  8|     Nixie|  Goldring| Dabshots|       DataScientist|\n",
      "|  9|Christophe| Churchill|Skynoodle|           Architect|\n",
      "| 10|     Booth| Leathwood|   Yambee| Construction Worker|\n",
      "+---+----------+----------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#current_df\n",
    "\n",
    "df_current=readfromDb(url,source_name,username,password)\n",
    "df_current.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+--------------------+-----+-------------------+-------------------+----+\n",
      "| id|first_name|last_name|   company|                role|sk_id|     effective_date|    expiration_date|flag|\n",
      "+---+----------+---------+----------+--------------------+-----+-------------------+-------------------+----+\n",
      "|  1|  Crawford|   Hurich|     Fadeo|             Manager|    1|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "|  2|    Karlik|  Barthot|    Kwideo|Construction Manager|    2|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "|  3|      Ivar|    Riggs|Fivebridge|     Project Manager|    3|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "|  4|     Elden|   Berger|     Jazzy|Construction Foreman|    4|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "|  5|       Jon| Bairstow|     Engla|             Creator|    5|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "+---+----------+---------+----------+--------------------+-----+-------------------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#history_df is incremental\n",
    "df_history=readfromDb(url,\"incremental\",username,password)\n",
    "df_history.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_sk\n",
    "def max_skey(df):\n",
    "    max_sk = df.agg({\"sk_id\": \"max\"}).collect()[0][0]\n",
    "    return max_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out open records from df_history\n",
    "# we don't need to do any changes in closed records\n",
    "df_history_open = df_history.where(col(\"flag\"))\n",
    "df_history_closed = df_history.where(col(\"flag\")==lit(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history_open_hash = rename(getHash(df_history_open, type2_cols), suffix=\"_history\", append=True)\n",
    "df_current_hash = rename(getHash(df_current, type2_cols), suffix=\"_current\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_action(df_history_open_hash):\n",
    "    df_merged = df_history_open_hash\\\n",
    "            .join(df_current_hash, col(\"id_current\") ==  col(\"id_history\"), how=\"full_outer\")\\\n",
    "            .withColumn(\"Action\", when(col(\"hash_md5_current\") == col(\"hash_md5_history\")  , 'NOCHANGE')\\\n",
    "            .when(col(\"id_current\").isNull(), 'DELETE')\\\n",
    "            .when(col(\"id_history\").isNull(), 'INSERT')\\\n",
    "            .otherwise('UPDATE'))\n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+--------------------+-----+-------------------+-------------------+----+\n",
      "| id|first_name|last_name|company|                role|sk_id|     effective_date|    expiration_date|flag|\n",
      "+---+----------+---------+-------+--------------------+-----+-------------------+-------------------+----+\n",
      "|  2|    Karlik|  Barthot| Kwideo|Construction Manager|    2|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "|  4|     Elden|   Berger|  Jazzy|Construction Foreman|    4|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "|  5|       Jon| Bairstow|  Engla|             Creator|    5|2023-11-28 14:16:10|9999-12-31 23:59:59|true|\n",
      "+---+----------+---------+-------+--------------------+-----+-------------------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##NO CHANGE\n",
    "df_merged=merge_action(df_history_open_hash)\n",
    "window_spec=Window.orderBy(\"id\")\n",
    "\n",
    "df_nochange=rename(df_merged.filter(col(\"Action\")=='NOCHANGE'), suffix=\"_history\", append=False).\\\n",
    "            select(df_history_open.columns)\n",
    "df_nochange.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------+---------------+--------------------+-------------+----------------------+-----------------------+------------+--------------------+----------+------------------+-----------------+---------------+--------------------+--------------------+--------+\n",
      "|id_history|first_name_history|last_name_history|company_history|        role_history|sk_id_history|effective_date_history|expiration_date_history|flag_history|    hash_md5_history|id_current|first_name_current|last_name_current|company_current|        role_current|    hash_md5_current|  Action|\n",
      "+----------+------------------+-----------------+---------------+--------------------+-------------+----------------------+-----------------------+------------+--------------------+----------+------------------+-----------------+---------------+--------------------+--------------------+--------+\n",
      "|         1|          Crawford|           Hurich|          Fadeo|             Manager|            1|   2023-11-28 11:52:36|    9999-12-31 23:59:59|        true|2f99b66c7dc424044...|         1|          Crawford|           Hurich|          Fadeo|              Worker|a1c45ea6e44893ca2...|  UPDATE|\n",
      "|         2|            Karlik|          Barthot|         Kwideo|Construction Manager|            2|   2023-11-28 11:52:36|    9999-12-31 23:59:59|        true|4b52ec7ffb751d320...|         2|            Karlik|          Barthot|         Kwideo|Construction Manager|4b52ec7ffb751d320...|NOCHANGE|\n",
      "|         3|              Ivar|            Riggs|     Fivebridge|     Project Manager|            3|   2023-11-28 11:52:36|    9999-12-31 23:59:59|        true|0032bf70e91199320...|      NULL|              NULL|             NULL|           NULL|                NULL|                NULL|  DELETE|\n",
      "|         4|             Elden|           Berger|          Jazzy|Construction Foreman|            4|   2023-11-28 11:52:36|    9999-12-31 23:59:59|        true|96f3aaec80867c60f...|         4|             Elden|           Berger|          Jazzy|Construction Foreman|96f3aaec80867c60f...|NOCHANGE|\n",
      "|         5|               Jon|         Bairstow|          Engla|             Creator|            5|   2023-11-28 11:52:36|    9999-12-31 23:59:59|        true|77eff8a36ef133771...|         5|               Jon|         Bairstow|          Engla|             Creator|77eff8a36ef133771...|NOCHANGE|\n",
      "|      NULL|              NULL|             NULL|           NULL|                NULL|         NULL|                  NULL|                   NULL|        NULL|                NULL|         6|           Ferrell|       Hungerford|        Feedbug|           Developer|6e561e52b17a2ac88...|  INSERT|\n",
      "|      NULL|              NULL|             NULL|           NULL|                NULL|         NULL|                  NULL|                   NULL|        NULL|                NULL|         7|            Evonne|           Benoit|        Blogtag|Construction Manager|e28d111e96709ff7d...|  INSERT|\n",
      "|      NULL|              NULL|             NULL|           NULL|                NULL|         NULL|                  NULL|                   NULL|        NULL|                NULL|         8|             Nixie|         Goldring|       Dabshots|       DataScientist|cc984b74db0e7688e...|  INSERT|\n",
      "|      NULL|              NULL|             NULL|           NULL|                NULL|         NULL|                  NULL|                   NULL|        NULL|                NULL|         9|        Christophe|        Churchill|      Skynoodle|           Architect|c28d58f46306399ce...|  INSERT|\n",
      "|      NULL|              NULL|             NULL|           NULL|                NULL|         NULL|                  NULL|                   NULL|        NULL|                NULL|        10|             Booth|        Leathwood|         Yambee| Construction Worker|30ad3f7e270d19da8...|  INSERT|\n",
      "+----------+------------------+-----------------+---------------+--------------------+-------------+----------------------+-----------------------+------------+--------------------+----------+------------------+-----------------+---------------+--------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------+--------------------+-------------------+-------------------+-----+----+\n",
      "| id|first_name| last_name|  company|                role|     effective_date|    expiration_date|sk_id|flag|\n",
      "+---+----------+----------+---------+--------------------+-------------------+-------------------+-----+----+\n",
      "|  6|   Ferrell|Hungerford|  Feedbug|           Developer|2023-11-28 14:20:30|9999-12-31 23:59:59|    6|true|\n",
      "|  7|    Evonne|    Benoit|  Blogtag|Construction Manager|2023-11-28 14:20:30|9999-12-31 23:59:59|    7|true|\n",
      "|  8|     Nixie|  Goldring| Dabshots|       DataScientist|2023-11-28 14:20:30|9999-12-31 23:59:59|    8|true|\n",
      "|  9|Christophe| Churchill|Skynoodle|           Architect|2023-11-28 14:20:30|9999-12-31 23:59:59|    9|true|\n",
      "| 10|     Booth| Leathwood|   Yambee| Construction Worker|2023-11-28 14:20:30|9999-12-31 23:59:59|   10|true|\n",
      "+---+----------+----------+---------+--------------------+-------------------+-------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##INSERT\n",
    "max_sk=max_skey(df_history)\n",
    "def insert(df):\n",
    "    df_insert = rename(df.filter(col(\"Action\") == 'INSERT'), suffix=\"_current\", append=False)\\\n",
    "                    .select(df_current.columns)\\\n",
    "                    .withColumn(\"effective_date\",date_format(current_timestamp(),DATE_FORMAT))\\\n",
    "                    .withColumn(\"expiration_date\",date_format(lit(def_timestamp),DATE_FORMAT))\\\n",
    "                    .withColumn(\"row_number\",row_number().over(window_spec))\\\n",
    "                    .withColumn(\"sk_id\",col(\"row_number\")+ max_sk)\\\n",
    "                    .withColumn(\"flag\", lit(True))\\\n",
    "                    .drop(\"row_number\")\n",
    "    return df_insert\n",
    "    \n",
    "df_insert=insert(df_merged)\n",
    "\n",
    "df_insert.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "max_sk=max_skey(df_insert)\n",
    "print(max_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+---------------+-----+-------------------+-------------------+-----+\n",
      "| id|first_name|last_name|   company|           role|sk_id|     effective_date|    expiration_date| flag|\n",
      "+---+----------+---------+----------+---------------+-----+-------------------+-------------------+-----+\n",
      "|  3|      Ivar|    Riggs|Fivebridge|Project Manager|    3|2023-11-28 14:16:10|2023-11-28 14:20:37|false|\n",
      "+---+----------+---------+----------+---------------+-----+-------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DELETED\n",
    "df_deleted = rename(df_merged.filter(col(\"action\") == 'DELETE'), suffix=\"_history\", append=False)\\\n",
    "                .select(df_history_open.columns)\\\n",
    "                .withColumn(\"expiration_date\", date_format(current_timestamp(),DATE_FORMAT))\\\n",
    "                .withColumn(\"flag\", lit(False))\n",
    "\n",
    "df_deleted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+-------+-----+-------------------+-------------------+-----+\n",
      "| id|first_name|last_name|company|   role|sk_id|     effective_date|    expiration_date| flag|\n",
      "+---+----------+---------+-------+-------+-----+-------------------+-------------------+-----+\n",
      "|  1|  Crawford|   Hurich|  Fadeo|Manager|    1|2023-11-28 14:16:10|2023-11-28 14:20:43|false|\n",
      "|  1|  Crawford|   Hurich|  Fadeo| Worker|   11|2023-11-28 14:20:43|9999-12-31 23:59:59| true|\n",
      "+---+----------+---------+-------+-------+-----+-------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##UPDATE\n",
    "\n",
    "df_update = rename(df_merged.filter(col(\"action\") == 'UPDATE'), suffix=\"_history\", append=False)\\\n",
    "                .select(df_history_open.columns)\\\n",
    "                .withColumn(\"expiration_date\", date_format(current_timestamp(),DATE_FORMAT))\\\n",
    "                .withColumn(\"flag\", lit(False))\\\n",
    "            .unionByName(\n",
    "            rename(df_merged.filter(col(\"action\") == 'UPDATE'), suffix=\"_current\", append=False)\\\n",
    "                .select(df_current.columns)\\\n",
    "                .withColumn(\"effective_date\",date_format(current_timestamp(),DATE_FORMAT))\\\n",
    "                .withColumn(\"expiration_date\",date_format(lit(def_timestamp),DATE_FORMAT))\\\n",
    "                .withColumn(\"row_number\",row_number().over(window_spec))\\\n",
    "                .withColumn(\"sk_id\",col(\"row_number\")+ max_sk)\\\n",
    "                .withColumn(\"flag\", lit(True))\\\n",
    "                .drop(\"row_number\")\n",
    "                )\n",
    "\n",
    "df_update.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+----------+--------------------+-----+-------------------+-------------------+-----+\n",
      "| id|first_name| last_name|   company|                role|sk_id|     effective_date|    expiration_date| flag|\n",
      "+---+----------+----------+----------+--------------------+-----+-------------------+-------------------+-----+\n",
      "|  2|    Karlik|   Barthot|    Kwideo|Construction Manager|    2|2023-11-28 14:16:10|9999-12-31 23:59:59| true|\n",
      "|  4|     Elden|    Berger|     Jazzy|Construction Foreman|    4|2023-11-28 14:16:10|9999-12-31 23:59:59| true|\n",
      "|  5|       Jon|  Bairstow|     Engla|             Creator|    5|2023-11-28 14:16:10|9999-12-31 23:59:59| true|\n",
      "|  6|   Ferrell|Hungerford|   Feedbug|           Developer|    6|2023-11-28 14:20:50|9999-12-31 23:59:59| true|\n",
      "|  7|    Evonne|    Benoit|   Blogtag|Construction Manager|    7|2023-11-28 14:20:50|9999-12-31 23:59:59| true|\n",
      "|  8|     Nixie|  Goldring|  Dabshots|       DataScientist|    8|2023-11-28 14:20:50|9999-12-31 23:59:59| true|\n",
      "|  9|Christophe| Churchill| Skynoodle|           Architect|    9|2023-11-28 14:20:50|9999-12-31 23:59:59| true|\n",
      "| 10|     Booth| Leathwood|    Yambee| Construction Worker|   10|2023-11-28 14:20:50|9999-12-31 23:59:59| true|\n",
      "|  3|      Ivar|     Riggs|Fivebridge|     Project Manager|    3|2023-11-28 14:16:10|2023-11-28 14:20:50|false|\n",
      "|  1|  Crawford|    Hurich|     Fadeo|             Manager|    1|2023-11-28 14:16:10|2023-11-28 14:20:50|false|\n",
      "|  1|  Crawford|    Hurich|     Fadeo|              Worker|   11|2023-11-28 14:20:50|9999-12-31 23:59:59| true|\n",
      "+---+----------+----------+----------+--------------------+-----+-------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##FINAL\n",
    "\n",
    "df_final = df_history_closed\\\n",
    "            .unionByName(df_nochange)\\\n",
    "            .unionByName(df_insert)\\\n",
    "            .unionByName(df_deleted)\\\n",
    "            .unionByName(df_update)\n",
    "\n",
    "\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "writetoDb(df_final,url,\"dest_scd\",username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_df=readfromDb(url,\"dest_scd\",username,password)\n",
    "writetoDb(incremental_df,url,\"incremental\",username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------+--------------------+-----+-------------------+-------------------+----+\n",
      "| id|first_name| last_name|  company|                role|sk_id|     effective_date|    expiration_date|flag|\n",
      "+---+----------+----------+---------+--------------------+-----+-------------------+-------------------+----+\n",
      "|  1|  Crawford|    Hurich|    Fadeo|              Worker|    6|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  2|    Karlik|   Barthot|   Kwideo|Construction Manager|    7|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  4|     Elden|    Berger|    Jazzy|Construction Foreman|    8|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  5|       Jon|  Bairstow|    Engla|             Creator|    9|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  6|   Ferrell|Hungerford|  Feedbug|           Developer|   10|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  7|    Evonne|    Benoit|  Blogtag|Construction Manager|   11|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  8|     Nixie|  Goldring| Dabshots|       DataScientist|   12|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "|  9|Christophe| Churchill|Skynoodle|           Architect|   13|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "| 10|     Booth| Leathwood|   Yambee| Construction Worker|   14|2023-11-28 11:58:55|9999-12-31 23:59:59|true|\n",
      "+---+----------+----------+---------+--------------------+-----+-------------------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_table=spark.read.format('jdbc'). \\\n",
    "     options(\n",
    "         url='jdbc:postgresql://localhost:5432/scd_2',\n",
    "         dbtable='information_schema.tables',\n",
    "         user='postgres',\n",
    "         password='Vish@08',\n",
    "         driver='org.postgresql.Driver'). \\\n",
    "     load().filter(col('table_name')=='dest_scd').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(table_catalog='scd_2', table_schema='public', table_name='dest_scd', table_type='BASE TABLE', self_referencing_column_name=None, reference_generation=None, user_defined_type_catalog=None, user_defined_type_schema=None, user_defined_type_name=None, is_insertable_into='YES', is_typed='NO', commit_action=None)]\n"
     ]
    }
   ],
   "source": [
    "print(dest_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
